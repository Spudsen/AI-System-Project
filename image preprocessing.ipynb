{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFont, ImageChops, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import ipykernel\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give File Locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with own directoires\n",
    "training_directory = r'C:\\Users\\Chris\\Documents\\Uni\\Programm for AI\\Final Test\\train'\n",
    "testing_directory = r'C:\\Users\\Chris\\Documents\\Uni\\Programm for AI\\Final Test\\test'\n",
    "valid_directory = r'C:\\Users\\Chris\\Documents\\Uni\\Programm for AI\\Final Test\\valid'\n",
    "output_directory =r'C:\\Users\\Chris\\Documents\\Uni\\Programm for AI\\Final Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Images into entropy levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    grayscale_image = image.convert(\"L\")\n",
    "    image_array = np.array(grayscale_image)\n",
    "    histogram, _ = np.histogram(image_array, bins=256, range=(0, 255), density=True)\n",
    "    entropy = -np.sum(histogram * np.log2(histogram + 1e-10))  # adding epsilon to avoid log(0)\n",
    "    return entropy\n",
    "\n",
    "def split_images_into_entropy_groups(directory, entropy_bins, output_dir):\n",
    "    # Create a new directory for the entropy groups\n",
    "    entropy_groups_dir = os.path.join(output_dir, 'entropy_groups')\n",
    "    os.makedirs(entropy_groups_dir, exist_ok=True)\n",
    "\n",
    "    for i in range(len(entropy_bins) - 1):\n",
    "        # Create directories for the entropy groups\n",
    "        os.makedirs(os.path.join(entropy_groups_dir, f'entropy_group_{i}'), exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            entropy = calculate_entropy(file_path)\n",
    "            # Assign the image to an entropy group\n",
    "            for i in range(len(entropy_bins) - 1):\n",
    "                if entropy_bins[i] <= entropy < entropy_bins[i + 1]:\n",
    "                    # Copy the image to the corresponding directory\n",
    "                    shutil.copy(file_path, os.path.join(entropy_groups_dir, f'entropy_group_{i}'))\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process {file_path}: {e}\")\n",
    "\n",
    "#entropy bins\n",
    "entropy_bins = [0, 2, 3, 3.5, 4, float('inf')] \n",
    "\n",
    "# Run the function for each directory\n",
    "split_images_into_entropy_groups(training_directory, entropy_bins, training_directory)\n",
    "split_images_into_entropy_groups(testing_directory, entropy_bins, testing_directory)\n",
    "split_images_into_entropy_groups(valid_directory, entropy_bins, valid_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-Split into Brightness Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_brightness(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    return np.mean(hsv[:,:,2])\n",
    "\n",
    "def categorize_images(path):\n",
    "    categories = ['very_dark_brightness', 'dark_brightness', 'extra_low_brightness', \n",
    "                  'very_low_brightness', 'low_brightness', 'medium_brightness', 'high_brightness']\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image = cv2.imread(os.path.join(path, filename))\n",
    "            brightness = calculate_brightness(image)\n",
    "            if brightness < 5:\n",
    "                category = categories[0]\n",
    "            elif brightness < 10:\n",
    "                category = categories[1]\n",
    "            elif brightness < 21:\n",
    "                category = categories[2]\n",
    "            elif brightness < 42:\n",
    "                category = categories[3]\n",
    "            elif brightness < 85:\n",
    "                category = categories[4]\n",
    "            elif brightness < 170:\n",
    "                category = categories[5]\n",
    "            else:\n",
    "                category = categories[6]\n",
    "\n",
    "            new_dir = os.path.join(path, category)\n",
    "            if not os.path.exists(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "\n",
    "            shutil.copy(os.path.join(path, filename), os.path.join(new_dir, filename))\n",
    "\n",
    "\n",
    "# Apply the categorization within the training, testing, and validation directories\n",
    "for i in range(5):\n",
    "    entropy_group_dir_train = os.path.join(training_directory, 'entropy_groups', f'entropy_group_{i}')\n",
    "    entropy_group_dir_test = os.path.join(testing_directory, 'entropy_groups', f'entropy_group_{i}')\n",
    "    entropy_group_dir_valid = os.path.join(valid_directory, 'entropy_groups', f'entropy_group_{i}')\n",
    "    if os.path.exists(entropy_group_dir_train):\n",
    "        categorize_images(entropy_group_dir_train)\n",
    "    if os.path.exists(entropy_group_dir_test):\n",
    "        categorize_images(entropy_group_dir_test)\n",
    "    if os.path.exists(entropy_group_dir_valid):\n",
    "        categorize_images(entropy_group_dir_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanse images according to brigtness-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Documents\\Uni\\Programm for AI\\completed test\n"
     ]
    }
   ],
   "source": [
    "# Function to increase brightness and contrast\n",
    "def adjust_brightness_contrast(input_image_path, output_image_path, brightness=1, contrast=1):\n",
    "    # Open the image file\n",
    "    img = Image.open(input_image_path)\n",
    "\n",
    "    # Enhance brightness\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(brightness)\n",
    "\n",
    "    # Enhance contrast\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(contrast)\n",
    "\n",
    "    # Save the edited image\n",
    "    img.save(output_image_path)\n",
    "    img.close()\n",
    "\n",
    "# Define the brightness and contrast values for each entropy group folder\n",
    "entropy_group_values = { #checked and cleared\n",
    "    'entropy_group_0': { \n",
    "        \"dark_brightness\": (1.25, 1.5), #checked and cleared\n",
    "        \"extra_low_brightness\": (1, 1.25), #checked and cleared\n",
    "        \"high_brightness\": (0.75, 1.5), #does not exist\n",
    "        \"low_brightness\": (1, 1.25), #does not exist\n",
    "        \"medium_brightness\": (1, 1), #does not exist\n",
    "        \"very_dark_brightness\": (2.25, 2.5), #checked and cleared\n",
    "        \"very_low_brightness\": (1, 0.75)  \n",
    "    },\n",
    "\n",
    "    'entropy_group_1': { \n",
    "        \"dark_brightness\": (1.75, 1.75), #checked and cleared\n",
    "        \"extra_low_brightness\": (1.3, 0.75), #checked and cleared\n",
    "        \"high_brightness\": (0.75, 1.5), #does not exist\n",
    "        \"low_brightness\": (0.75, 1.5), #checked and cleared\n",
    "        \"medium_brightness\": (1, 1), #does not exist\n",
    "        \"very_dark_brightness\": (2.25, 2.5), #still to dark, cannot justify increase due to fidelity loss\n",
    "        \"very_low_brightness\": (1, 0.75) #checked and cleared\n",
    "    },\n",
    "\n",
    "    'entropy_group_2': { #checked and cleared\n",
    "        \"dark_brightness\": (2, 2), #checked and cleared\n",
    "        \"extra_low_brightness\": (1.25, 1.25), #checked and cleared\n",
    "        \"high_brightness\": (0.75, 1.5), #checked and cleared\n",
    "        \"low_brightness\": (1, 1.25), #checked and cleared\n",
    "        \"medium_brightness\": (1, 1), #checked and cleared\n",
    "        \"very_dark_brightness\": (2.25, 2.5), #checked and cleared\n",
    "        \"very_low_brightness\": (1, 1.25) #checked and cleared\n",
    "    },\n",
    "\n",
    "    'entropy_group_3': { #checked and cleared\n",
    "        \"dark_brightness\": (2, 2), #checked and cleared\n",
    "        \"extra_low_brightness\": (1.5, 1.25), #checked and cleared\n",
    "        \"high_brightness\": (0.75, 1.75), #checked and cleared\n",
    "        \"low_brightness\": (1, 1.25), #checked and cleared\n",
    "        \"medium_brightness\": (1, 1), #checked and cleared\n",
    "        \"very_dark_brightness\": (3, 2),  #still to dark, cannot justify increase due to fidelity loss\n",
    "        \"very_low_brightness\": (1, 1.25) #checked and cleared\n",
    "    },\n",
    "\n",
    "    'entropy_group_4': { \n",
    "        \"dark_brightness\": (2, 2),  #checked and cleared\n",
    "        \"extra_low_brightness\": (1.5, 1.25), #checked and cleared\n",
    "        \"high_brightness\": (0.75, 2), #checked and cleared\n",
    "        \"low_brightness\": (1, 1.25), #checked and cleared\n",
    "        \"medium_brightness\": (1, 1.15), #checked and cleared\n",
    "        \"very_dark_brightness\": (2.25, 2.5), #does not exist\n",
    "        \"very_low_brightness\": (1, 1.25) #checked and cleared\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define a list of the master directories\n",
    "master_directories = [training_directory, testing_directory, valid_directory]\n",
    "\n",
    "# Loop through each master directory\n",
    "for master_directory in master_directories:\n",
    "    # Loop through each entropy group folder in the dictionary\n",
    "    for entropy_group_folder, folder_values in entropy_group_values.items():\n",
    "        # Define the directory path for the current entropy group folder\n",
    "        dir_path = os.path.join(master_directory, 'entropy_groups', entropy_group_folder)\n",
    "\n",
    "        # Loop through each brightness folder in the dictionary\n",
    "        for folder, (brightness_value, contrast_value) in folder_values.items():\n",
    "            # Define the input and output paths\n",
    "            input_dir_path = os.path.join(dir_path, folder)\n",
    "            output_dir_path = os.path.join(input_dir_path, 'edited_images')\n",
    "\n",
    "            # Remove the directory if it exists\n",
    "            if os.path.exists(output_dir_path):\n",
    "                shutil.rmtree(output_dir_path)\n",
    "\n",
    "            # Create a new directory for the edited images\n",
    "            os.makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "            # Loop through each file in the directory\n",
    "            for filename in os.listdir(input_dir_path):\n",
    "                # Check if the file is an image\n",
    "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                    # Define the input and output paths\n",
    "                    input_image_path = os.path.join(input_dir_path, filename)\n",
    "                    output_image_path = os.path.join(output_dir_path, filename)\n",
    "\n",
    "                    # Adjust brightness and contrast of the image\n",
    "                    adjust_brightness_contrast(input_image_path, output_image_path, brightness=brightness_value, contrast=contrast_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move files to master location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_augmented_images(master_directories, output_directory):\n",
    "    # Define the new directories\n",
    "    new_directories = ['new_training', 'new_testing', 'new_valid']\n",
    "\n",
    "    # Loop through each master directory\n",
    "    for master_directory, new_directory in zip(master_directories, new_directories):\n",
    "        # Define the new directory path\n",
    "        new_dir_path = os.path.join(output_directory, new_directory)\n",
    "\n",
    "        # Create the new directory if it doesn't exist\n",
    "        if not os.path.exists(new_dir_path):\n",
    "            os.makedirs(new_dir_path)\n",
    "\n",
    "        # Loop through each entropy group folder in the dictionary\n",
    "        for entropy_group_folder in entropy_group_values.keys():\n",
    "            # Define the directory path for the current entropy group folder\n",
    "            dir_path = os.path.join(master_directory, 'entropy_groups', entropy_group_folder)\n",
    "\n",
    "            # Loop through each brightness folder in the dictionary\n",
    "            for folder in entropy_group_values[entropy_group_folder].keys():\n",
    "                # Define the input and output paths\n",
    "                input_dir_path = os.path.join(dir_path, folder, 'edited_images')\n",
    "                output_dir_path = os.path.join(new_dir_path, entropy_group_folder, folder)\n",
    "\n",
    "                # Create the output directory if it doesn't exist\n",
    "                if not os.path.exists(output_dir_path):\n",
    "                    os.makedirs(output_dir_path)\n",
    "\n",
    "                # Loop through each file in the directory\n",
    "                for filename in os.listdir(input_dir_path):\n",
    "                    # Check if the file is an image\n",
    "                    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                        # Define the input and output paths\n",
    "                        input_image_path = os.path.join(input_dir_path, filename)\n",
    "                        output_image_path = os.path.join(output_dir_path, filename)\n",
    "\n",
    "                        # Move the image to the new directory\n",
    "                        shutil.copy(input_image_path, output_image_path)\n",
    "\n",
    "        # Copy the _annotations.csv file to the new directory\n",
    "        annotations_file_path = os.path.join(master_directory, '_annotations.csv')\n",
    "        if os.path.exists(annotations_file_path):\n",
    "            shutil.copy(annotations_file_path, new_dir_path)\n",
    "\n",
    "def move_images_to_top(master_directories, output_directory):\n",
    "    # Define the new directories\n",
    "    new_directories = ['new_training', 'new_testing', 'new_valid']\n",
    "\n",
    "    # Loop through each master directory\n",
    "    for master_directory, new_directory in zip(master_directories, new_directories):\n",
    "        # Define the new directory path\n",
    "        new_dir_path = os.path.join(output_directory, new_directory)\n",
    "\n",
    "        # Loop through each entropy group folder in the dictionary\n",
    "        for entropy_group_folder in entropy_group_values.keys():\n",
    "            # Define the directory path for the current entropy group folder\n",
    "            dir_path = os.path.join(new_dir_path, entropy_group_folder)\n",
    "\n",
    "            # Find all images in the entropy group folder and its subfolders\n",
    "            images = glob.glob(os.path.join(dir_path, '**', '*.jpg'), recursive=True)\n",
    "            images += glob.glob(os.path.join(dir_path, '**', '*.png'), recursive=True)\n",
    "\n",
    "            # Move each image to the top level of the new directory\n",
    "            for image_path in images:\n",
    "                shutil.move(image_path, new_dir_path)\n",
    "\n",
    "            # Delete the entropy group folder\n",
    "            shutil.rmtree(dir_path)\n",
    "\n",
    "move_augmented_images(master_directories, output_directory)\n",
    "move_images_to_top(master_directories, output_directory)\n",
    "training_directory = os.path.join(output_directory, 'new_training')\n",
    "testing_directory = os.path.join(output_directory, 'new_testing')\n",
    "valid_directory = os.path.join(output_directory, 'new_valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize images and update CSV and fill in blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images_and_boxes(directory, size=(256, 256)):\n",
    "    # Define the column names\n",
    "    column_names = ['filename', 'x1', 'y1', 'x2', 'y2', 'label']\n",
    "\n",
    "    # Load the annotations file\n",
    "    df = pd.read_csv(os.path.join(directory, '_annotations.csv'), names=column_names)\n",
    "\n",
    "    # Replace 'humerus' with 'humerus fracture'\n",
    "    df['label'] = df['label'].replace('humerus', 'humerus fracture')\n",
    "\n",
    "    # Loop through each unique filename in the DataFrame\n",
    "    for filename in df['filename'].unique():\n",
    "        # Load the image\n",
    "        image = Image.open(os.path.join(directory, filename))\n",
    "\n",
    "        # Get the original image size\n",
    "        original_size = image.size\n",
    "\n",
    "        # Resize the image\n",
    "        image = image.resize(size)\n",
    "        image.save(os.path.join(directory, filename))\n",
    "\n",
    "        # Adjust the bounding boxes\n",
    "        df.loc[df['filename'] == filename, ['x1', 'x2']] = (df.loc[df['filename'] == filename, ['x1', 'x2']] * size[0] / original_size[0]).round()\n",
    "        df.loc[df['filename'] == filename, ['y1', 'y2']] = (df.loc[df['filename'] == filename, ['y1', 'y2']] * size[1] / original_size[1]).round()\n",
    "\n",
    "    # Check for images in the directory that are not in the DataFrame\n",
    "    for image_file in glob.glob(os.path.join(directory, '*.jpg')):\n",
    "        filename = os.path.basename(image_file)\n",
    "        if filename not in df['filename'].values:\n",
    "            # Add the missing image to the DataFrame with the label 'None'\n",
    "            df = df.append({'filename': filename, 'label': 'None'}, ignore_index=True)\n",
    "\n",
    "    # Save the adjusted annotations\n",
    "    df.to_csv(os.path.join(directory, '_annotations.csv'), index=False)\n",
    "\n",
    "resize_images_and_boxes(training_directory)\n",
    "resize_images_and_boxes(testing_directory)\n",
    "resize_images_and_boxes(valid_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a group of inverted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_invert_images(input_directory, output_directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Copy the _annotations.csv file to the new directory\n",
    "    shutil.copy(os.path.join(input_directory, '_annotations.csv'), output_directory)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Define the input and output paths\n",
    "            input_image_path = os.path.join(input_directory, filename)\n",
    "            output_image_path = os.path.join(output_directory, filename)\n",
    "\n",
    "            # Load the image\n",
    "            image = Image.open(input_image_path)\n",
    "\n",
    "            # Invert the image\n",
    "            inverted_image = ImageOps.invert(image)\n",
    "\n",
    "            # Save the inverted image\n",
    "            inverted_image.save(output_image_path)\n",
    "\n",
    "# Use the function to copy and invert the images\n",
    "copy_and_invert_images('new_training', 'new_training_inverted')\n",
    "copy_and_invert_images('new_testing', 'new_testing_inverted')\n",
    "copy_and_invert_images('new_valid', 'new_valid_inverted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an overlayed image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_images(input_directory1, input_directory2, output_directory):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Copy the _annotations.csv file from the first input directory to the new directory\n",
    "    shutil.copy(os.path.join(input_directory1, '_annotations.csv'), output_directory)\n",
    "\n",
    "    # Loop through each file in the first input directory\n",
    "    for filename in os.listdir(input_directory1):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Define the input paths\n",
    "            input_image_path1 = os.path.join(input_directory1, filename)\n",
    "            input_image_path2 = os.path.join(input_directory2, filename)\n",
    "\n",
    "            # Load the images\n",
    "            image1 = Image.open(input_image_path1).convert('RGB')\n",
    "            image2 = Image.open(input_image_path2).convert('RGB')\n",
    "\n",
    "            # Overlay the images\n",
    "            overlayed_image = ImageChops.darker(image1, image2)\n",
    "\n",
    "            # Save the overlayed image\n",
    "            overlayed_image.save(os.path.join(output_directory, filename))\n",
    "\n",
    "# Use the function to overlay the images\n",
    "overlay_images('new_training', 'new_training_inverted', 'new_training_overlayed')\n",
    "overlay_images('new_testing', 'new_testing_inverted', 'new_testing_overlayed')\n",
    "overlay_images('new_valid', 'new_valid_inverted', 'new_valid_overlayed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove absolute black (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define source and target directories \n",
    "# src_dir = 'all_resized_overlay'\n",
    "# tgt_dir = 'all_resized_overlay_background_removed'\n",
    "\n",
    "# # Create target directory if it doesn't exist\n",
    "# if not os.path.exists(tgt_dir):\n",
    "#     os.makedirs(tgt_dir)\n",
    "\n",
    "# # Loop over all files in the source directory\n",
    "# for filename in os.listdir(src_dir):\n",
    "#     if filename.endswith('.jpg'): \n",
    "#         # Open each image file\n",
    "#         img = Image.open(os.path.join(src_dir, filename)).convert(\"RGBA\")\n",
    "        \n",
    "#         # Create a new sequence object by replacing all black pixels with transparent ones\n",
    "#         datas = []\n",
    "#         for item in img.getdata():\n",
    "#             # change all black (also shades of blacks)\n",
    "#             # pixels to transparent\n",
    "#             if item[0] in list(range(0, 50)):\n",
    "#                 datas.append((255, 255, 255, 0))\n",
    "#             else:\n",
    "#                 datas.append(item)\n",
    "                \n",
    "#         # Create new image and save\n",
    "#         img.putdata(datas)\n",
    "#         img_rgb = img.convert(\"RGB\")  # convert back to RGB before saving as JPEG\n",
    "#         img_rgb.save(os.path.join(tgt_dir, filename))  # Save as JPEG\n",
    "#         img.save(os.path.join(tgt_dir, os.path.splitext(filename)[0] + '.png'))  # Save as PNG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
